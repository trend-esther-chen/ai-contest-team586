# Question Solver

This script automates the process of solving questions stored as .txt files in a specified directory, and stores the solutions in py and CSV file.


- [Question Solver](#question-solver)
  - [Requirements](#requirements)
  - [Installation](#installation)
  - [Usage](#usage)
    - [(IMPORTANT) Contest Format Requirements](#important-contest-format-requirements)
  - [Docker](#docker)
    - [Building the Docker Image](#building-the-docker-image)
    - [Running the Docker Container](#running-the-docker-container)
  - [Evaluation](#evaluation)


## Requirements
Python 3.9 or above

## Installation

First, clone the repository to your local machine:

```bash
git clone git@adc.github.trendmicro.com:AIContest-2023/AI-Contest-Baseline.git
```

Then navigate to the directory:

```bash
cd AI-Contest-Baseline
```

Install the required packages using pip:

```bash
pip install -r requirements.txt
```

Before running the script, you need to set several environment variables in `.env`:

```bash
DEPLOYMENT_NAME=your_deployment_name
OPENAI_API_TYPE="azure"
OPENAI_API_VERSION="2023-07-01-preview"
OPENAI_API_BASE=your_openai_api_base
OPENAI_API_KEY=your_openai_api_key
```

Replace `your_deployment_name`, `your_openai_api_base` and `your_openai_api_key` with your actual values.

For how to get these values, please refer to [this document](https://wiki.jarvis.trendmicro.com/display/2OC/A.+Azure+OpenAI+QuickStart).

## Usage

Put your question files in .txt format into the `./questions` directory. The solutions will be automatically saved in `./solutions`.

To run the script with the default parameters:

```bash
python main.py
```

If you want to see more detailed logs during the solving process, you can use the `--debug` option:

```bash
python main.py --debug
```

The debug mode will display the detailed log records of the question-answering process.

If you want to specify a different path for the question files and the solution file, you can use the `--question-path` and `--solution-save-path` options:

```bash
python main.py --question-path your-question-folder --solution-save-path your-solution-folder
```

This will use the files in `your-question-folder` as the questions, and save the solutions in `your-solution-folder`.

### (IMPORTANT) Contest Format Requirements

The contest server uses the `Question_FILE` environment variable to determine the path for the problem file. Afterward, it will call your provided `./main.sh` and expects you to generate a solution at the location indicated by the `Solution_FILE` environment variable.

**Input**: Path provided by `Question_FILE` environment variable.
* Example: `./questions/question.txt`

**Output**: Path provided by `Solution_FILE` environment variable.
* Example: `./solutions/solution.py`

When executed, the game server runs: 
```bash
bash ./main.sh "evalmessage"
```

**About `evalmessage`:** 
This is the information on the execution result of the previous run of `solution.py` by the game server. Contestants should consider how to utilize this information themselves.

**Hint:** The game server will by default generate and run the `solution.py` for the same question five times.

## Docker

This project can use Docker to get solutions. Below are the instructions to build and run your Docker container.

### Building the Docker Image

Run the following command in the root directory of this project that contains the `Dockerfile`:

```bash
docker build -t ai-contest .
```

### Running the Docker Container
First, make sure that questions directory `./questions` and `./solutions` directory has been created (to save the solutions).

Then, you can run your Docker container with the following command:

```bash
docker run --mount type=bind,source="$(pwd)"/questions,target=/app/questions --mount type=bind,source="$(pwd)"/solutions,target=/app/solutions ai-contest
```

Please ensure the relevant environment variables in the `.env` file are set before building the Docker image.

In this command, the `--mount` arguments are used to bind your host's questions and solutions directories to the `/app/questions` and `/app/solutions` directories inside the Docker container. This way, when the container runs, it will read the questions from the questions directory on your host and write the solutions to the solutions directory on your host.

This README assumes that you are in an environment where Docker commands can be run. If you do not have Docker installed, you might need to [install Docker](https://docs.docker.com/engine/install/) first.

## Evaluation

You can also evaluate the solutions provided by the ChatGPT. 

To do this, please follow the steps below:

1. Prepare your evaluation script, which should be a Python unittest script that tests the function generated by ChatGPT.
2. Name your evaluation script with the same filename as the corresponding question file(txt) in `./questions` directory.
3. Put your evaluation script into the `./eval` directory.

Here is an example of how to structure your evaluation script (You can also refer to the existing examples in the `eval/` directory):

```python
import unittest

class TestXXX(unittest.TestCase):

    def test_examples(self):
        self.assertEqual(solution(9), 2)
        self.assertEqual(solution(529), 4)
```

Once you have your evaluation scripts prepared and placed in the `./eval` directory, you can run the evaluation by:

```bash
python eval.py --solution-path your-solution-file
```

Replace `your-solution-file` with the path to your solution file. If you don't specify the --solution-path option, the script will use `./solutions/20230726_174815.csv` as the default.

This will execute your unittest scripts and provide the test results, allowing you to see how well the generated code performed.
